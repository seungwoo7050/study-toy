# Web + Native 비디오 에디터 기초 가이드  
`web-native-video-editor-basics.md`

> 이 문서는 "웹 기반 비디오 에디터를 설계/구현할 때 필요한 개념"을 정리한 개념서다.  
> 이미 React/Node 기초와 미니 프로젝트들을 끝냈다고 가정한다.

---

## 0. 이 문서로 어디까지 가는가

### 0.1 최종 목표

이 문서를 끝냈을 때 스스로 할 수 있어야 하는 것:

1. "웹 기반 비디오 에디터가 어떻게 동작하는지"를 **그림으로 설명**할 수 있다.
2. 프로젝트 / 타임라인 / 트랙 / 클립 / 이펙트 모델을 **JSON 구조로 설계**할 수 있다.
3. "업로드 → 프록시/썸네일 → 타임라인 편집 → 렌더" 파이프라인을 말로 풀 수 있다.
4. 몇 가지 대표적인 편집 동작(트림, 합치기, 자막, 속도)이 **FFmpeg 옵션/필터로 어떻게 매핑되는지** 대략 연결해서 생각할 수 있다.
5. 프론트(React) / 백엔드(Node) / 네이티브(FFmpeg/N-API) 역할을 분리해서 설명할 수 있다.

이 수준이면 `native-video-editor` 같은 프로젝트의 설계 문서와 코드를 읽어가면서 "왜 이렇게 나눴는지" 이해하는 데 무리는 없다.

### 0.2 학습 대상 프로젝트 예시

- `native-video-editor`
  - React 기반 타임라인 UI
  - Node/Express 백엔드
  - FFmpeg 기반 렌더링 + 일부 네이티브 모듈(N-API) 사용

### 0.3 선행 완료 전제

이 문서는 다음을 이미 한 번은 해봤다고 가정한다.

- `react-spa-basics.md` 수준
  - 컴포넌트/상태/라우팅, API 연동 기초
- `node-express-ts-basics.md` 수준
  - REST API, 미들웨어, 간단한 파일 업로드, DB 연동
- Docker + Postgres + Redis 기본 사용
  - `docker compose up`, 간단한 DB 접속 정도

FFmpeg를 직접 써본 경험이 없더라도 상관 없다.  
다만, "커맨드 한 줄이라도 쳐본 경험"이 있으면 이해가 더 빠르다.

### 0.4 이 문서에서 다루지 않는 것들

의도적으로 **안** 다루는 것:

- 코덱/컨테이너 이론 깊은 내용 (H.264 내부 구조, GOP, CABAC 등)
- WebGL 셰이더/렌더링 파이프라인 상세
- 브라우저별 동영상 재생 호환성 문제 전체 (Safari/DRM 등)
- 대규모 분산 렌더 팜(k8s, auto-scaling, region 분산 등)

이 문서는 **제품용 비디오 편집기 전체 기술 스택**이 아니라,  
"포트폴리오용 웹/네이티브 비디오 에디터" 수준에 필요한 개념에 맞춰져 있다.

---

## 1. 웹 기반 비디오 에디터 전체 그림

### 1.1 타겟 사용자 / 유스케이스

대표적으로 이런 시나리오를 상정하면 된다.

- 짧은 클립(몇 초~몇 분)들을 모아서 하나의 영상으로 만들고 싶다.
- 일부 구간만 잘라내고(트림), 자막/텍스트를 얹고, 속도를 약간 바꾸고 싶다.
- 브라우저에서 대략 편집하고, 서버에서 렌더해서 결과 파일을 내려받고 싶다.

즉, **프리미어/다빈치의 전체 기능**이 아니라:

- 간단한 컷 편집
- 자막/텍스트
- 기본 이펙트(페이드 인/아웃)
- 속도 조절

정도까지 커버하는 "라이트 버전"을 전제로 잡는 것이 현실적이다.

### 1.2 대략적인 UI 구성 요소

일반적인 구조:

- **미리보기(Preview) 영역**
  - 현재 타임라인 위치의 영상/오디오를 재생
- **타임라인(Timeline)**
  - 트랙/클립을 시간 축으로 보여주는 곳
- **자산 패널(Assets)**
  - 업로드된 원본 미디어(영상/음성/이미지)를 리스트로 보여줌
- **인스펙터/설정 패널(Inspector)**
  - 선택한 클립/이펙트의 상세 설정(텍스트, 위치, 색, 속도 등)을 편집

이 네 가지가 명확하게 분리되어야:

- 도메인 모델 설계
- 상태 관리
- 리렌더링 비용
을 컨트롤하기가 쉬워진다.

### 1.3 전체 아키텍처 레이어

아주 단순화하면 이렇게 나뉜다:

- **프론트엔드 (React)**
  - 타임라인/클립/이펙트를 조작하는 UI
  - 사용자의 편집 동작 → "타임라인 JSON" 상태 변경
  - 미리보기 플레이어 제어

- **백엔드 (Node/Express)**
  - 프로젝트/타임라인/자산/렌더 잡 API
  - 업로드 처리 (원본/프록시/썸네일 트리거)
  - 렌더 잡 큐 관리

- **네이티브/미디어 레이어**
  - FFmpeg 프로세스 실행 또는 N-API 모듈
  - 썸네일/파형/프록시 생성
  - 최종 렌더링

- **스토리지**
  - 원본/프록시/결과 영상 파일 저장소 (local/S3 등)
  - 메타데이터/타임라인/잡 상태를 저장하는 DB (Postgres 등)

이 네 레이어 사이에 **단순한 JSON 계약**만 오고가게 설계하는 게 목표다.

### 1.4 하나의 프로젝트 라이프사이클

한 유저가 프로젝트 하나를 시작해서 결과 파일을 받을 때까지:

1. **프로젝트 생성**
   - 제목/해상도/FPS 등 기본 설정
2. **미디어 업로드**
   - 영상/음성/이미지 파일 업로드
   - 서버에서 썸네일/파형/프록시 생성
3. **타임라인 편집**
   - 트랙/클립을 추가/이동/삭제
   - 이펙트/자막/속도 등을 조정
   - 프리뷰로 확인
4. **렌더 요청**
   - 현재 타임라인 상태를 바탕으로 렌더 잡 생성
   - 백엔드/워커가 FFmpeg 등으로 렌더 진행
5. **결과 다운로드**
   - 렌더 완료 후, 결과 파일을 링크로 제공

이 라이프사이클을 머릿속에 고정해 놓고 나머지 섹션을 보면 구조가 훨씬 정리된다.

---

## 2. 타임라인 도메인 모델

비디오 에디터의 핵심은 **타임라인 도메인 모델**이다.  
여기서 삐끗하면 나머지가 다 꼬인다.

### 2.1 핵심 개념 정리

일반적으로 최소 이 정도는 필요하다:

- **Project**
  - 하나의 편집 작업 단위 (유저 입장에서 "프로젝트")
  - 해상도, FPS, 기본 배경색, 오디오 샘플레이트 등 공통 설정을 가진다.

- **Sequence (또는 Composition)**
  - 프로젝트 안의 "타임라인 하나" 정도로 생각해도 된다.
  - 간단한 제품이면 `Project` 하나당 `Sequence` 하나로 시작해도 된다.

- **Track**
  - 시간 축 위에 깔리는 레이어
  - 종류:
    - VIDEO
    - AUDIO
    - TEXT/SUBTITLE
  - 순서(위/아래)가 있고, 그 순서가 렌더 순서/레이어 순서를 결정한다.

- **Clip**
  - 트랙 위에 놓이는 조각
  - 특정 **소스 미디어의 일부 구간**을 참조하면서, 위치/길이/이펙트 정보를 가진다.

### 2.2 시간 표현 방식

시간을 표현하는 방법은 크게 두 가지:

- **초 단위(float / double)**
  - 예: `startSec = 12.5`, `durationSec = 3.0`
  - 계산은 편한데, 부동소수점 오차 신경을 써야 한다.

- **프레임 단위(integer)**
  - 예: `startFrame = 375`, `durationFrames = 90`
  - FPS(Frames Per Second)를 기본으로 깔고 가야 한다.
  - 편집 도메인에서는 프레임 단위가 더 자연스럽다.

단순화해서:

- 내부 모델은 "프레임 단위"
- UI에서만 초/타임코드로 변환

하는 방식을 많이 쓴다.

타임코드 예시: `00:01:23:12` (시:분:초:프레임)

### 2.3 클립 모델

클립은 대략 이런 정보가 필요하다:

- `clipId`
- `trackId`
- **타임라인 좌표**
  - `startFrame` (타임라인 기준)
  - `durationFrames`
- **소스 미디어 참조**
  - `assetId` (원본/프록시 파일에 대한 참조)
  - `inFrame` / `outFrame` (소스 기준)
- **이펙트 정보**
  - opacity, transform, color grading 간단 파라미터 등

예시(단순화된 JSON):

```json
{
  "clipId": "clip-1",
  "trackId": "video-track-1",
  "startFrame": 0,
  "durationFrames": 150,
  "assetId": "asset-video-1",
  "inFrame": 30,
  "outFrame": 180,
  "effects": {
    "opacity": 1.0,
    "scale": 1.0,
    "position": { "x": 0, "y": 0 }
  }
}
```

### 2.4 이펙트 / 전환 / 자막 모델

**이펙트(Effect)**

* 단일 클립에 붙는 "필터" 느낌.
* 예:

  * 밝기/대비/색상
  * 속도(재생 속도)
  * 간단한 transform(위치/스케일/회전)

**전환(Transition)**

* 두 클립 사이에 적용되는 효과.
* 예:

  * Crossfade (A → B 페이드)
  * Fade in/out

표현 방식:

* 별도 `Transition` 객체를 두고,

  * `fromClipId`, `toClipId`, `durationFrames`, `type`
* 또는, 클립 끝/시작 구간에 플래그로 표현.

**자막/Text**

* TEXT 트랙에 **TextClip**으로 넣는 게 깔끔하다.
* 필드 예:

  * 텍스트 내용
  * 폰트/크기/색
  * 화면 내 위치(anchor, x/y)
  * 내부적으로는 나중에 FFmpeg `drawtext` 등으로 맵핑된다.

### 2.5 실습 1: 타임라인 JSON 스키마 설계

직접 해볼 것:

1. **최소 필드만 가진 Project/Track/Clip JSON 스키마**를 문서형식으로 적어본다.
2. "3개의 클립이 있는 1개의 비디오 트랙 + 1개의 자막 트랙" 예시 데이터를 손으로 만들어본다.
3. "타임라인을 저장/로드할 때 이 JSON이 그대로 DB에 들어간다"고 생각하고,
   변경에 강할지, 너무 하드코딩인지 확인해본다.

실제 구현은 나중 문제고,
**JSON으로 모델이 깔끔하게 떨어지느냐**가 더 중요하다.

---

## 3. 업로드 / 자산(Asset) 관리

### 3.1 업로드 패턴

최소한 고려할 패턴:

* **단일 업로드**

  * 작은 파일(수십 MB 수준)에는 이걸로 충분하다.
  * 프론트에서 `<input type="file">` + `FormData` → 백엔드로 전송.

* **청크 업로드(Chunked)**

  * 수백 MB~수 GB까지 고려한다면 필요해진다.
  * 파일을 여러 조각(chunk)으로 나눠서 전송하고, 서버에서 합친다.
  * 재시도/중단 재개(resume)를 붙이기 쉬워진다.

초기 프로젝트라면:

* 단일 업로드로 시작 → 나중에 필요하면 청크 업로드로 확장.

### 3.2 원본 / 프록시 / 썸네일 구분

**원본(original)**

* 유저가 업로드한 그대로.
* 품질 보존, 최종 렌더에도 사용.

**프록시(proxy)**

* 저해상도/저비트레이트 버전.
* 프리뷰/편집 시 사용해서 CPU/네트워크 부담을 줄인다.

**썸네일(thumbnail)**

* 타임라인/자산 패널에서 보여줄 작은 이미지.
* 특정 프레임(예: 1초 지점)을 캡처해서 만든다.

핵심은:

* **원본은 되도록 건드리지 않고**,
* 편집/프리뷰는 프록시/썸네일 위에서 한다는 것.

### 3.3 파일/디렉터리 구조 설계

예시:

```text
/media-root/
  projects/
    {projectId}/
      assets/
        original/
          {assetId}.mp4
          {assetId}.wav
        proxy/
          {assetId}_720p.mp4
        thumbnail/
          {assetId}.jpg
      renders/
        {renderJobId}.mp4
      temp/
        ...
```

디렉터리 레벨에서:

* 프로젝트 단위로 격리
* 역할(원본/프록시/썸네일/렌더/임시)을 분리

해두면 관리가 훨씬 편해진다.

### 3.4 스토리지 선택

* **로컬 디스크**

  * 개발/소규모 서비스에 적합
  * 경로 기반 관리만 잘해도 충분함
* **오브젝트 스토리지 (S3 등)**

  * 서버 수가 많거나, 대용량이 필요하면 자연스럽게 이쪽
  * URL 기반 접근, 퍼블릭/프라이빗 권한 관리 필요

이 문서에서는 "로컬 디스크 또는 단일 버킷" 정도를 가정한다.
중요한 건 "경로/키 전략"이지, 구체적인 클라우드 서비스가 아니다.

### 3.5 실습 2: 파일 경로 설계 표 만들기

직접 설계해볼 것:

* 입력: `projectId`, `assetId`, `renderJobId`
* 출력: 각각에 대해

  * 원본 파일 경로
  * 프록시 파일 경로
  * 썸네일 파일 경로
  * 렌더 결과 파일 경로

을 표 형태로 적어본다.

예:

| 타입    | 예시 경로                                                         |
| ----- | ------------------------------------------------------------- |
| 원본    | `/media/projects/{projectId}/assets/original/{assetId}.mp4`   |
| 프록시   | `/media/projects/{projectId}/assets/proxy/{assetId}_720p.mp4` |
| 썸네일   | `/media/projects/{projectId}/assets/thumbnail/{assetId}.jpg`  |
| 렌더 결과 | `/media/projects/{projectId}/renders/{renderJobId}.mp4`       |

이 정도를 머릿속에서 항상 자동으로 떠올릴 수 있는 상태가 되면 충분하다.

---

## 4. 미리보기 / 재생 구조

### 4.1 브라우저 비디오 플레이어 구성

기본은 그냥 `<video>` 태그다:

```html
<video
  src="..."
  controls
  muted
></video>
```

React 기준으로는:

* `<video ref={videoRef} />`로 DOM을 잡고
* `videoRef.current.currentTime`, `play()`, `pause()` 등으로 제어한다.

관건은:

* **타임라인의 플레이헤드 위치**와
* `<video>`의 `currentTime`

을 어떻게 동기화할지다.

### 4.2 타임라인과 재생 위치 연동

대략적인 상태 구조:

```ts
type TimelineState = {
  fps: number;
  currentFrame: number;
  tracks: Track[];
  // ...
};

type PlayerState = {
  playing: boolean;
  playbackRate: number;
};
```

* 타임라인에서 드래그로 스크럽 → `currentFrame` 변경
* `currentFrame` 변경 → `video.currentTime = currentFrame / fps`
* 재생 버튼 → `playing = true`로 두고, `requestAnimationFrame` 또는 타이머로 currentFrame 증가

실제 구현은 프로젝트에서 정하지만,
**"프론트에서는 currentFrame이 진짜 상태고, video는 그걸 반영하는 뷰"**라고 생각하면 구조가 잡힌다.

### 4.3 오디오 파형 / 썸네일 생성 개요

오디오 파형(waveform):

* 서버에서 원본/프록시 음원을 분석해서 **샘플링된 amplitude 배열**을 만든다.
* 프론트는 이 배열을 Canvas나 SVG로 렌더링.
* 타임라인에서 오디오 클립의 시각적인 가이드 역할.

썸네일:

* FFmpeg로 일정 간격 프레임을 뽑아서 이미지들 생성
* 타임라인 스크럽 시 특정 썸네일을 보여줄 수도 있고,
  자산 패널에서 대표 이미지로 사용할 수도 있다.

이 둘은 "있으면 UX가 크게 개선되는 추가 요소"이지만,
없어도 시스템은 동작한다. 우선순위를 정할 때 참고하면 된다.

### 4.4 미리보기 품질 전략

미리보기에서 중요하게 보는 값:

* 해상도 (360p/480p/720p 등)
* 비트레이트
* GOP/키프레임 간격 (너무 길면 시크가 느리다)

일반적인 전략:

* 프리뷰용 프록시는 저해상도/저비트레이트로 인코딩
* **시크/재생이 빠르고 가벼운 것**을 우선한다.
* 최종 렌더 품질은 별도로 설정한다.

프론트에서는:

* "프리뷰 모드"와 "최종 품질 모드"를 분리한다.
* 이 가이드는 프리뷰 중심으로 생각하면 된다.

### 4.5 실습 3: 간단한 타임라인 + 비디오 동기 데모 설계

구현까지는 아니고, 구조 설계만 해본다.

1. React 기준으로 상태 구조를 정의한다.

   * `timelineState: { fps, currentFrame, clips[] }`
   * `playerState: { playing, playbackRate }`
2. "재생 버튼을 누르면 어떤 순서로 상태/DOM이 바뀌는지"를 글로 정리한다.

   * `playing = true`
   * 일정 주기마다 `currentFrame += fps * dt`
   * `video.currentTime` 갱신
3. "타임라인 위를 드래그해서 스크럽할 때" 동작도 같이 정의한다.

   * 드래그 위치 → `currentFrame` 계산
   * `video.currentTime` 즉시 반영
   * 재생 중이면 일시정지할지, 그대로 재생할지 정책

이 설계가 깔끔하게 떨어지면, 실제 구현은 그다음 문제다.

---

## 5. 렌더링 파이프라인 (FFmpeg 중심)

### 5.1 컨테이너 / 코덱 / 스트림 개념

최소한 이 정도는 알고 가야 한다:

* **컨테이너(Container)**

  * mp4, mkv, mov 같은 "껍데기"
  * 안에 여러 스트림(영상/음성/자막)이 들어있다.

* **코덱(Codec)**

  * 영상: H.264, H.265 등
  * 음성: AAC, Opus 등
  * 인코딩/디코딩 방식

* **스트림(Stream)**

  * 한 컨테이너 안에 있는 개별 트랙
  * 예: 비디오 1개 + 오디오 1개

이걸 다 깊게 할 필요는 없고,
"편집 결과는 결국 `타임라인 → 하나의 컨테이너 + 여러 스트림`으로 떨어진다" 정도만 이해하면 된다.

### 5.2 편집 동작 → FFmpeg 개념 매핑

대표적인 편집 동작을 FFmpeg 개념으로 어떻게 볼지 정리해보자.

* **트림 / 컷**

  * 특정 구간만 자르기
  * FFmpeg에서는 `-ss`, `-to`, `-t` 옵션 또는 필터로 처리

* **여러 클립 붙이기(concat)**

  * 연속된 타임라인으로 만들어야 함
  * 방법:

    * concat demuxer (파일 리스트 기반)
    * concat 필터 (필터 그래프 내부에서 체인)

* **속도 조절**

  * 영상: `setpts` 필터
  * 오디오: `atempo` 필터

* **자막/텍스트 오버레이**

  * `drawtext` 필터 또는 자막 파일(burn-in)

타임라인 도메인 모델에서:

* 클립/이펙트를 JSON으로 표현하고,
* 백엔드/워커가 이 JSON을 읽어서 **FFmpeg 명령/필터 그래프**로 변환하는 구조를 붙이면 된다.

### 5.3 렌더 잡(Job) 구조

렌더링은 **"잡(job)" 단위로 비동기 처리**하는 게 일반적이다.

필요한 정보:

* `renderJobId`
* `projectId`
* 입력:

  * 타임라인 스냅샷(JSON)
  * 출력 해상도/코덱/비트레이트 설정
* 상태:

  * QUEUED / RUNNING / SUCCEEDED / FAILED / CANCELED
  * 진행률(0~100 또는 rough 값)
* 아웃풋:

  * 결과 파일 경로
  * duration, size, 썸네일 등 메타데이터

예시(단순 JSON):

```json
{
  "renderJobId": "job-123",
  "projectId": "proj-1",
  "timelineSnapshot": { /* ... */ },
  "output": {
    "width": 1920,
    "height": 1080,
    "codec": "h264",
    "bitrate": "5000k"
  },
  "status": "RUNNING",
  "progress": 42,
  "resultPath": null
}
```

중요한 건:

* 렌더 시작 시점에 "타임라인 스냅샷"을 같이 저장해서,
  렌더 중에 유저가 타임라인을 바꿔도 영향이 없게 하는 것.

### 5.4 진행 상태(progress) 관리

FFmpeg는 보통 `stderr`에 이런 로그를 계속 찍는다:

* 현재 처리 중인 프레임/시간
* 속도
* 추정 남은 시간

워커 프로세스는:

1. FFmpeg 프로세스를 실행한다.
2. stderr/log를 읽으면서 현재 진행 상태를 추정한다.
3. 추정 결과를 DB/Redis 같은 데 업데이트한다.
4. 프론트는 폴링 또는 WebSocket/SSE로 progress를 읽어간다.

간단한 패턴:

* "현재 처리 중인 시간 / 전체 duration" → 진행률
* 대충이라도 되는 게 중요하지, 정확한 %는 크게 의미 없다.

### 5.5 실습 4: 렌더 잡 JSON 스키마 설계

해볼 것:

1. `RenderJob` JSON 스키마를 직접 적어본다.

   * 필수 필드: `renderJobId`, `projectId`, `status`, `progress`, `outputPath`
   * 옵션 필드: `errorMessage`, `startedAt`, `finishedAt`
2. "타임라인 스냅샷"을 어디까지 포함할지 결정한다.

   * 전체 프로젝트 JSON?
   * 현재 Sequence 하나만?
3. "프론트에서 이 JSON만 받아도 렌더 상태 화면을 그릴 수 있는지"를 체크한다.

---

## 6. 서버 / 네이티브 아키텍처

### 6.1 Node API 레이어

역할:

* 인증/인가 (로그인/프로젝트 접근 제어)
* 프로젝트/타임라인/자산 CRUD API
* 업로드 엔드포인트
* 렌더 잡 생성/상태 조회 API

엔드포인트 예시:

* `POST /projects`
* `GET /projects/{id}`
* `PUT /projects/{id}/timeline`
* `POST /projects/{id}/assets`
* `POST /projects/{id}/render-jobs`
* `GET /render-jobs/{jobId}`

중요한 건:

* **타임라인과 렌더를 전부 JSON 계약으로 묶는다**는 것.
* 서버는 "타임라인 JSON을 저장하고, 렌더 잡을 큐에 넣는 역할"에 집중한다.

### 6.2 FFmpeg 래핑 방식 (프로세스 / N-API)

두 가지 방향:

1. **프로세스 실행 방식**

   * Node에서 `child_process.spawn`으로 FFmpeg 바이너리를 호출
   * 장점:

     * 구현 간단
     * FFmpeg 버전/옵션을 OS 레벨에서 통제 가능
   * 단점:

     * 프로세스 관리/리소스 제어를 잘 해야 함

2. **N-API 네이티브 모듈 방식**

   * C/C++로 FFmpeg를 래핑한 모듈을 작성
   * Node에서 직접 함수 호출
   * 장점:

     * 오버헤드 줄이기 가능
     * 더 세밀한 제어
   * 단점:

     * 빌드/배포 복잡도↑
     * 크로스 플랫폼 고려 필요

처음에는 **프로세스 실행 방식**으로 시작하고,
병목이 분명해지면 일부를 N-API로 옮기는 구조가 현실적이다.

### 6.3 백그라운드 워커 / 잡 큐

렌더링 작업은 HTTP 요청/응답 안에서 끝낼 게 아니다.
기본 패턴:

* `render_jobs` 테이블/컬렉션 + 큐(redis, DB, 메시지 브로커…)를 둔다.
* API 서버에서는:

  * 렌더 요청을 받으면 `RenderJob` 레코드 생성
  * 상태를 `QUEUED`로 두고, 워커가 볼 수 있는 큐에 넣는다.
* 워커 프로세스는:

  * 큐에서 잡을 꺼내서 FFmpeg 실행
  * 진행 상태/결과를 지속적으로 업데이트
  * 완료 시 `SUCCEEDED`/`FAILED`로 갱신

상태 전이 예:

* `QUEUED` → `RUNNING` → `SUCCEEDED`
* `QUEUED` → `RUNNING` → `FAILED`

동시 렌더 수를 제한하려면:

* 워커 프로세스 개수
* FFmpeg 프로세스 동시 실행 수

만 조절하면 된다.

### 6.4 실습 5: 잡 큐 상태 다이어그램 스케치

해볼 것:

1. `RenderJobStatus` enum을 정의한다.

   * `QUEUED`, `RUNNING`, `SUCCEEDED`, `FAILED`, `CANCELED` 정도
2. 상태 전이 다이어그램을 그린다.

   * 어떤 이벤트(API 호출/워커 완료/타임아웃)가 어떤 전이를 트리거하는지
3. "API 서버 / 워커 / 프론트" 세 주체가
   각 상태에서 어떤 역할을 하는지 간단히 표로 정리한다.

목표는:

* 코드 없이도 "렌더 플로우가 어떻게 흘러가는지"를 입으로 설명할 수 있는 상태.

---

## 7. 성능 / 리소스 / 장애 대응 (심화)

> 이 섹션은 "프로젝트가 실제로 무거운 파일을 돌리기 시작했을 때" 생기는 문제에 관한 내용이다.  
> 필수는 아니지만, 한 번쯤 읽어두면 이후 병목 잡을 때 도움이 된다.

### 7.1 대용량 파일 처리 시 고려사항

**1) I/O vs CPU vs 메모리**

영상 편집/렌더링은 거의 항상:

- 디스크 I/O: 대용량 파일 읽기/쓰기
- CPU: 디코딩/인코딩/필터
- 메모리: 버퍼, 썸네일/파형 데이터

이 세 가지가 동시에 눌린다.  
어디가 병목인지 모르면 "그냥 느린 시스템"이 된다.

실제로는:

- 원본/프록시/렌더 결과가 모두 **같은 디스크**에 있을 때
- 동시에 여러 렌더를 돌리면 **디스크 I/O가 먼저 죽는다**

그래서:

- 개발/테스트에서는 **한 번에 1~2개의 렌더만** 돌리는 구조로 시작하는 게 안전하다.
- 나중에 여유가 되면:
  - 원본/프록시/렌더 결과를 다른 디스크/스토리지로 분리
  - 워커/서버 간 분산을 고민

**2) 스트리밍 기반 처리**

FFmpeg는 기본적으로 "스트리밍 방식"으로 움직인다.

- 한 번에 전체 파일을 메모리에 올리지 않는다.
- 그러나, 우리가 썸네일/파형/메타데이터를 **한 번에 다 읽어 들이면** 그게 병목이 된다.

전략:

- 파형/썸네일 생성도 가능하면 **단계적으로/필요할 때만** 수행.
- UI에서 "이 자산이 실제로 타임라인에 쓰일 때" 생성하게 하는 것도 한 방법.

**3) 프리뷰용 길이 제한**

초기 버전에서는:

- 프리뷰/에디팅 대상 영상 길이에 **소프트 제한**을 두는 게 좋다.
  - 예: 10분 이하
- 길이가 길어질수록,
  - 썸네일/파형 생성 시간
  - 렌더 시간
  - 디스크 사용량  
  이 모두가 고통을 준다.

프로덕션 제품이 아니므로, 과감하게 "최대 길이 제한"을 명시하는 게 정신건강에 좋다.

---

### 7.2 동시 렌더 제한 전략

**1) 단순 제한부터**

가장 단순한 전략:

- 워커 프로세스당 **동시 렌더 수 = 1**로 시작.
- 나중에 CPU/디스크 여유 보고, 2/3개까지 늘려 본다.

구현은:

- 잡 큐에서 꺼낼 때 "현재 실행 중인 렌더 수"를 확인하고,
- 일정 수 이상이면 큐에서 꺼내지 않도록 하면 된다.

**2) 자원 기반 제한**

좀 더 나아가면:

- CPU 코어 수, 디스크 사용량, 평균 렌더 시간 등을 보고 **동적으로 동시 실행 수를 조절**할 수 있다.

하지만 이건 이 프로젝트 스코프를 넘기 쉬우니:

- **초기 버전은 "고정 값"으로 두고**
- 그 값이 얼마나 버티는지 지표를 보고 조정하는 선에서 마무리하는 게 현실적이다.

**3) 우선순위 (선택)**

한 번 더 가면:

- "짧은 작업"을 먼저 처리하거나,
- "최근 편집한 프로젝트" 위주로 우선순위를 줄 수도 있다.

이것도 역시 제품/서비스 단계에서 고민할 문제고,  
포트폴리오 수준에서는 "FIFO + 동시 렌더 수 제한"만으로 충분하다.

---

### 7.3 임시 파일/캐시 정책

렌더/프록시/썸네일을 만들다 보면 **임시 파일이 엄청 쌓인다**.

정책을 안 세우면:

- 디스크 꽉 차고
- 어디서 뭐가 쓰이는지 모르게 된다.

**1) temp 디렉터리 고정**

프로젝트별로:

```text
/media-root/projects/{projectId}/temp/
```

이런 식으로 temp 디렉터리를 강제로 하나 두고,
임시 파일은 **무조건 여기만** 쓰게 한다.

**2) 수명(TTL) 정책**

임시 파일은:

* 렌더 완료 후 바로 지우거나,
* "마지막으로 사용된 시점 기준 N일" 이후 자동 삭제하는 정책이 필요하다.

방법:

* 워커/크론 잡으로 주기적으로 temp 내 파일의 `mtime`(수정 시간)을 보고 삭제
* "현재 진행 중인 렌더에서 쓰는 파일은 건드리지 않는" 조건 필요

**3) 디버그 vs 릴리즈 모드**

디버깅 시엔 임시 파일을 남기고 싶을 수도 있다.

* `DEBUG_MEDIA_TEMP=true` 환경 변수 같은 걸 두고,

  * true면 temp를 남기고,
  * false면 성공/실패 후 temp 정리.

이 정도만 해도 "쌓이기만 하는 임시 파일 지옥"은 피할 수 있다.

---

### 7.4 장애 시나리오

대표적인 장애 시나리오를 몇 개만 짚자.

**1) 렌더 중 서버(워커) 다운**

* 상황:

  * 워커가 FFmpeg 돌리던 중 프로세스가 죽음.
* 필요:

  * 잡 상태가 **RUNNING**에서 **STUCK** 상태로 방치되지 않도록 해야 한다.

전략:

* 각 잡에 `heartbeat` 느낌의 `updatedAt` 필드를 두고,

  * 일정 시간 이상 `RUNNING`인데 업데이트가 없으면

    * `FAILED`로 바꾸거나
    * `QUEUED`로 되돌려서 다시 시도.

**2) 렌더 실패 (FFmpeg 에러)**

예:

* 지원하지 않는 코덱
* 손상된 파일
* 디스크 공간 부족

전략:

* 실패 시:

  * `status = FAILED`
  * `errorMessage` 저장(FFmpeg stderr 일부)
* 프론트엔드는 이 메시지를 읽고:

  * 사용자에게 "이 영상은 지원되지 않음" / "관리자 문의" 등 표시.

**3) 프록시/썸네일 생성 실패**

* 원본은 괜찮은데, 프록시/썸네일 생성이 실패할 수 있다.
* 이 경우:

  * 자산은 등록되지만, 편집 UX가 떨어질 수 있다.

전략:

* 실패 시:

  * 자산 상태를 `DEGRADED` 등으로 표시
  * 프론트에서 "썸네일/파형 없음" 상태를 자연스럽게 처리할 수 있게 한다.
* 나중에 **재시도 버튼**을 프로젝트 화면에 넣어도 좋다.

**4) 디스크 부족**

* 가장 현실적인 장애.
* FFmpeg가 실패하기 전에 이미 시스템 전체가 이상해질 수 있다.

최소:

* 렌더/프록시/썸네일 실행 전에 **디스크 여유 용량 체크**
* 여유가 부족하면 바로 `FAILED`로 돌리고, "관리자에게 알림" 정도로 처리.

---

### 7.5 모니터링할 지표

프로덕션 수준까지는 아니더라도, 최소한 이 정도는 보고 있으면 좋다.

**1) 렌더 관련**

* **렌더 시간 분포**

  * 평균 / p95 / p99
* **성공/실패 비율**
* **렌더 큐 대기 시간**

  * `createdAt` → 실제 시작 시간 사이의 차이

**2) 자산 관련**

* 프로젝트당 평균 자산 수
* 자산당 평균 용량
* 전체 스토리지 사용량

**3) 시스템 관련**

* 디스크 사용률
* CPU / 메모리 사용률 (워커 노드 기준)

이 지표를 완벽하게 수집할 필요는 없다.
단지 "문제가 생겼을 때 뭐부터 볼지" 감을 잡기 위한 기준점이다.

---

## 8. 자주 하는 실수 & 안티패턴 (심화)

> 이 섹션은 "이 도메인에서 자주 망하는 패턴"을 리스트로 모아둔 곳이다.
> 읽어보고 ‘이거 우리 설계에서 벌써 하고 있나?’ 체크하는 용도로 쓰면 된다.

### 8.1 원본 파일 직접 덮어쓰기

안티패턴:

* 트림/인코딩/이펙트를 적용하면서 **원본 파일을 덮어쓰는 것**.

문제:

* 취소/되돌리기가 사실상 불가능
* 편집 과정에서 생긴 버그/실패가 원본까지 망가뜨림

원칙:

* 원본은 **절대 불변(read-only)** 취급
* 모든 편집 결과는 **새 파일**로 만든다.
* 프록시도 원본에서 파생된 **별도 파일**로 관리.

### 8.2 타임라인 모델을 단순 배열로만 설계

안티패턴:

* `clips: Clip[]` 하나만 두고,

  * track 개념 없이 "start/end 시간만 있는 구조"로 모든 걸 때려넣기.

문제:

* 레이어링(위/아래), 오디오/비디오 분리, 자막 레이어 등을 표현하기 힘들다.
* 나중에 "트랙 추가" 같은 요구가 생기면 구조 전체를 갈아엎어야 한다.

원칙:

* 최소한:

  * 프로젝트
  * 시퀀스(선택)
  * 트랙 (type + order)
  * 트랙 안의 클립들
    구조까지는 처음부터 분리해 두는 게 낫다.

### 8.3 프론트에서 모든 계산/렌더를 시도

안티패턴:

* "요즘 브라우저/WebAssembly/WebGL 쎄니까 다 브라우저에서 해보자" 식 접근.

문제:

* 프리뷰 수준의 일부 효과는 가능하지만,
* **실제 인코딩/최종 렌더**를 전부 브라우저에 맡기면 기기 성능·브라우저 제약에 너무 영향을 받는다.
* 모바일/낮은 사양 환경에서는 무용지물.

원칙:

* 브라우저:

  * 타임라인 편집/프리뷰
  * 최대한 가벼운 범위의 효과/렌더(짧은 구간, 낮은 해상도)
* 서버/네이티브:

  * 최종 렌더링 책임

### 8.4 렌더 실패/중단 상태 관리 없음

안티패턴:

* "렌더 시작 → 끝나면 SUCCESS 아니면 그냥 HTTP 에러" 정도로만 처리하고,
* 중간 실패/중단 상태를 남기지 않는 것.

문제:

* 유저 입장: "왜 안 되는지 모르는 시스템"
* 운영 입장: "어디서 계속 터지는지" 알 수 없음

원칙:

* 모든 렌더 잡은 상태 머신을 가져야 한다.

  * QUEUED / RUNNING / SUCCEEDED / FAILED / CANCELED
* 실패 시:

  * 이유(errorMessage)를 기록
* 중단/다운:

  * 일정 시간 이상 업데이트 없으면 FAILED 또는 재시도

---

## 9. FAQ / 자기점검 (심화)

### 9.1 개념 체크 질문 리스트

이 질문들에 답할 수 있으면, 이 가이드에서 다룬 개념은 어느 정도 잡힌 것이다.

1. **타임라인/트랙/클립 모델**

   * Q: 하나의 프로젝트 안에서 타임라인/트랙/클립은 어떤 관계로 연결되는가?
   * Q: 자막/텍스트는 어떤 트랙/클립 구조로 표현하는 게 자연스러운가?

2. **업로드/자산/스토리지**

   * Q: 원본/프록시/썸네일을 왜 분리해서 관리해야 하는가?
   * Q: 프로젝트 ID / 자산 ID / 렌더 잡 ID만 있으면, 각 파일의 경로를 어떻게 계산할 수 있는가?

3. **미리보기/재생**

   * Q: 타임라인의 `currentFrame`과 `<video>`의 `currentTime`을 어떻게 동기화하는가?
   * Q: 프리뷰와 최종 렌더의 품질/성능 트레이드오프는 어떻게 설계하는가?

4. **렌더 파이프라인**

   * Q: 트림/합치기/속도/자막 같은 편집 동작이 FFmpeg 옵션/필터로 어떻게 맵핑되는지 예를 들어 설명할 수 있는가?
   * Q: 렌더 잡 JSON에는 어떤 정보들이 들어가야 프론트에서 상태를 그릴 수 있는가?

5. **서버/네이티브/장애 대응**

   * Q: Node API 서버 / 백그라운드 워커 / FFmpeg 프로세스의 책임은 각각 무엇인가?
   * Q: 렌더 중 워커가 죽었을 때, 시스템은 어떤 상태 전이/재시도 전략을 가져야 하는가?

### 9.2 프로젝트 시작 전 체크리스트

실제 `native-video-editor` 프로젝트에 들어가기 전에, 아래 항목들을 체크해보자.

* [ ] Project / Track / Clip / Effect / Subtitle 도메인 모델을 **직접 다이어그램/JSON으로 한번 그려 봤다.
* [ ] 프로젝트별 파일/디렉터리 구조를 **경로 문자열 형태로 정리**해 봤다.
* [ ] "업로드 → 썸네일/프록시 생성 → 타임라인 편집 → 렌더 → 다운로드" 플로우를 **글로 설명**할 수 있다.
* [ ] `RenderJob` 상태(QUEUED/RUNNING/SUCCEEDED/FAILED)의 상태 전이를 **테이블/다이어그램으로 정리**해 봤다.
* [ ] 최소 하나의 "랜덤 영상 파일"을 머릿속에 두고,

  * 이 파일이 업로드되면 어디에 저장되고,
  * 프록시/썸네일이 어디에 생기고,
  * 편집/렌더를 거친 뒤 결과가 어디에 놓이는지
    **한 줄 흐름으로 설명**할 수 있다.

이 체크리스트를 전부 "예"라고 답할 수 있으면,
이제 실제 코드/설계 문서로 들어가도 된다.
부족한 항목이 있다면, 해당 섹션으로 돌아가서 **도메인 모델/플로우를 다시 그려보는 것**이 더 빠르다.